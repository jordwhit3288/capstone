library(readxl)
library(dplyr)
library(ggplot2)
library(plotly)
library(Rmisc)
library(readxl)
covid_data <- read_excel("covid-data.xlsx",
col_types = c("text", "text", "text",
"text", "numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
summary(covid_data)
#changing the date column class from "character" to "date" type
class(covid_data$date)
covid_data$date <- as.Date(covid_data$date)
class(covid_data$date)
# covid_data has 50,350 obs of 41 variables
# interpolation via spline method for the missing values in chosen columns
# library(zoo)
# covid_data$life_expectancy <-  na.spline(covid_data$life_expectancy)
# summary(covid_data$life_expectancy)
##### HDI ####
hdi_check <- filter(covid_data, covid_data$human_development_index >= 0.915)
unique(hdi_check$location)
hdi_check = mutate(hdi_check, percent_pop_infected = hdi_check$total_cases/hdi_check$population)
hdi_check$percent_pop_infected = hdi_check$percent_pop_infected * 100
hdi_check$percent_pop_infected = round(hdi_check$percent_pop_infected, 2)
# dropped columns with more than 50% missing data
hdi_check <-  hdi_check[,!sapply(hdi_check, function(x) mean(is.na(x)))>0.5]
summary(hdi_check)
which(is.na(hdi_check$gdp_per_capita)) ### this shows it is Lichenstein
hdi_check<- subset(hdi_check, hdi_check$location !="Liechtenstein")
hdi_check<- subset(hdi_check, hdi_check$location !="Hong Kong")
summary(hdi_check)
unique(covid_data$location)
unique(hdi_check$location)
#write.csv(x=hdi_check, file="Covid_Cleansed_HDI_Check.csv")
# load the dataset
data(PimaIndiansDiabetes)
# ensure results are repeatable
set.seed(7)
library(mlbench)
library(caret)
install.packages("mlbench")
# load the dataset
data(PimaIndiansDiabetes)
# load the dataset
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(diabetes~., data=hdi_check, method="lvq", preProcess="scale", trControl=control)
# train the model
model <- train(hdi_check~., data=hdi_check, method="lvq", preProcess="scale", trControl=control)
# train the model
model <- train(new_cases~., data=hdi_check, method="lvq", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# train the model
model <- train(new_cases~., data=hdi_check, method="lvq", preProcess="scale", trControl=control, na.rm = TRUE)
# ensure results are repeatable
hdi_check_no_missing <- na.omit(hdi_check)
# train the model
model <- train(new_cases~., data=hdi_check, method="lvq", preProcess="scale", trControl=control)
View(hdi_check_no_missing)
# train the model
model <- train(new_cases~., data=hdi_check_no_missing, method="lvq", preProcess="scale", trControl=control)
res = cor(hdi_check)
res = cor(hdi_check[3:])
View(hdi_check)
cols = c(5, 24)
res = cor(hdi_check[-cols])
new_hdi_check = hdi_check[-cols])
new_hdi_check = hdi_check[-cols]
res = cor(new_hdi_check)
View(new_hdi_check)
cols = c(1:4, 24)
new_hdi_check = hdi_check[-cols]
res = cor(new_hdi_check)
cols = c(1:4, 25)
new_hdi_check = hdi_check[-cols]
res = cor(new_hdi_check)
library(corrplot)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
round(res, 2)
View(hdi_check)
covid = read_csv("CLEANSED_Covid_Cleansed_HDI_Check.csv")
library(readr)
covid_cleansed <- read_csv("covid_cleansed.csv")
library(readxl)
covid_test <- read_excel("covid_test.xlsx")
View(covid_test)
library(readxl)
covid_test <- read_excel("covid_test.xlsx")
View(covid_test)
covid_test
covid_test <- mice(data,m=5,maxit=50,meth='pmm',seed=500)
install.packages("mice")
library(mice)
covid_test <- mice(data,m=5,maxit=50,meth='pmm',seed=500)
covid_test <- mice(covid_test,m=5,maxit=50,meth='pmm',seed=500)
View(covid_test)
covid_test <- mice(covid_test,m=5,maxit=50,meth='pmm',seed=500)
covid_test <- mice(covid_test,m=5,maxit=50,meth='rf',seed=500)
View(covid_test)
library(readxl)
covid_test <- read_excel("covid_test.xlsx")
View(covid_test)
imp2 <- mice(covid_test, maxit = 5,
predictorMatrix = predM,
method = meth, print =  FALSE)
imp2 <- mice(covid_test, maxit = 5,
method = meth, print =  FALSE)
imp2 <- mice(covid_test, maxit = 5)
library(zoo)
covid_test$new_tests = na.spline(covid_test$new_tests)
View(covid_test)
covid_test <- read_excel("covid_test.xlsx")
covid_test$total_tests = na.spline(covid_test$total_tests)
#deleting rows with missingness
hdi_cleansed <- hdi_check[complete.cases(hdi_cleansed), ]
#deleting rows with missingness
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
View(hdi_cleansed)
unique(hdi_cleansed$location)
#deleting rows with missingness
hdi_check_cleanse_test <- filter(covid_data, covid_data$human_development_index >= 0.9)
unique(hdi_cleansed$location)
unique(hdi_check_cleanse_test$location)
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
unique(hdi_cleansed$location)
#deleting rows with missingness
hdi_check_cleanse_test <- filter(covid_data, covid_data$human_development_index >= 0.88)
unique(hdi_check_cleanse_test$location)
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
unique(hdi_cleansed$location)
##### new _cases boxplot !!! this is good
ggplot(hdi_check, aes(x=location, y=new_cases)) +
geom_boxplot() +
scale_y_continuous(trans = "log2") +
my_theme
##### my theme #####
my_theme = theme(axis.ticks = element_line(colour = "gray4"),
panel.grid.major = element_line(linetype = "dotted"),
axis.text.x = element_text(vjust = 0.5, angle = 90), panel.background = element_rect(fill = "aliceblue",
linetype = "longdash"), plot.background = element_rect(fill = "white"))
##### new _cases boxplot !!! this is good
ggplot(hdi_check, aes(x=location, y=new_cases)) +
geom_boxplot() +
scale_y_continuous(trans = "log2") +
my_theme
install.packages("imputeTS")
library(imputeTS)
na_ma(hdi_check$new_tests)
na_ma(hdi_check$new_tests, weighting = "simple")
hdi_check$new_tests = na_ma(hdi_check$new_tests, weighting = "simple")
View(hdi_check)
library(readxl)
covid_data <- read_excel("covid-data.xlsx",
col_types = c("text", "text", "text",
"text", "numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
summary(covid_data)
#changing the date column class from "character" to "date" type
class(covid_data$date)
covid_data$date <- as.Date(covid_data$date)
class(covid_data$date)
# covid_data has 50,350 obs of 41 variables
# interpolation via spline method for the missing values in chosen columns
# library(zoo)
# covid_data$life_expectancy <-  na.spline(covid_data$life_expectancy)
# summary(covid_data$life_expectancy)
##### HDI ####
hdi_check <- filter(covid_data, covid_data$human_development_index >= 0.915)
unique(hdi_check$location)
hdi_check = mutate(hdi_check, percent_pop_infected = hdi_check$total_cases/hdi_check$population)
hdi_check$percent_pop_infected = hdi_check$percent_pop_infected * 100
hdi_check$percent_pop_infected = round(hdi_check$percent_pop_infected, 2)
# dropped columns with more than 50% missing data
hdi_check <-  hdi_check[,!sapply(hdi_check, function(x) mean(is.na(x)))>0.5]
summary(hdi_check)
which(is.na(hdi_check$gdp_per_capita)) ### this shows it is Lichenstein
hdi_check<- subset(hdi_check, hdi_check$location !="Liechtenstein")
hdi_check<- subset(hdi_check, hdi_check$location !="Hong Kong")
summary(hdi_check)
unique(covid_data$location)
unique(hdi_check$location)
#write.csv(x=hdi_check, file="Covid_Cleansed_HDI_Check.csv")
unique(hdi_check$location)
View(hdi_check)
View(hdi_check_no_missing)
write.csv(x=hdi_check_no_missing, file="hdi_check_no_missing.csv")
unique(hdi_check$gdp_per_capita)
cor(hdi_cleansed)
View(hdi_cleansed)
unique(hdi_cleansed$location)
cols = c(1:4, 25)
hdi_cleansed = hdi_cleansed[-cols]
cor(hdi_cleansed)
lm(formula = hdi_cleansed$new_cases ~ hdi_cleansed$date + I(hdi_cleansed$date^2) +
I(hdi_cleansed$date^3))
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
cols = c(1:3, 25)
hdi_cleansed = hdi_cleansed[-cols]
lm(formula = hdi_cleansed$new_cases ~ hdi_cleansed$date + I(hdi_cleansed$date^2) +
I(hdi_cleansed$date^3))
hdi_cleansed$date^2
ggplot(hdi_cleansed,aes(date,new_cases)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
geom_point()
ggplot(hdi_cleansed,aes(date,new_cases)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
geom_point() +
scale_y_continuous(trans = "log2")
ggplot(hdi_cleansed,aes(date,new_cases)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
geom_line() +
scale_y_continuous(trans = "log2")
lm(formula = hdi_cleansed$new_cases ~ hdi_cleansed$stringency_index + I(hdi_cleansed$stringency_index^2) +
I(hdi_cleansed$stringency_index^3))
test_poly = lm(formula = hdi_cleansed$new_cases ~ hdi_cleansed$stringency_index + I(hdi_cleansed$stringency_index^2) +
I(hdi_cleansed$stringency_index^3))
summary(test_poly)
test_poly = lm(formula = hdi_cleansed$new_cases ~ hdi_cleansed$new_tests + I(hdi_cleansed$new_tests^2) +
I(hdi_cleansed$new_tests^3))
summary(test_poly)
ggplot(hdi_cleansed,aes(date,new_cases)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
geom_line() +
scale_y_continuous(trans = "log2")
cor(hdi_cleansed)
hdi_cleansed
cor(hdi_cleansed[2:])
library(readxl)
covid_data <- read_excel("covid-data.xlsx",
col_types = c("text", "text", "text",
"text", "numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
summary(covid_data)
#changing the date column class from "character" to "date" type
class(covid_data$date)
covid_data$date <- as.Date(covid_data$date)
class(covid_data$date)
# covid_data has 50,350 obs of 41 variables
# interpolation via spline method for the missing values in chosen columns
# library(zoo)
# covid_data$life_expectancy <-  na.spline(covid_data$life_expectancy)
# summary(covid_data$life_expectancy)
##### HDI ####
hdi_check <- filter(covid_data, covid_data$human_development_index >= 0.915)
unique(hdi_check$location)
hdi_check = mutate(hdi_check, percent_pop_infected = hdi_check$total_cases/hdi_check$population)
hdi_check$percent_pop_infected = hdi_check$percent_pop_infected * 100
hdi_check$percent_pop_infected = round(hdi_check$percent_pop_infected, 2)
# dropped columns with more than 50% missing data
hdi_check <-  hdi_check[,!sapply(hdi_check, function(x) mean(is.na(x)))>0.5]
summary(hdi_check)
which(is.na(hdi_check$gdp_per_capita)) ### this shows it is Lichenstein
hdi_check<- subset(hdi_check, hdi_check$location !="Liechtenstein")
hdi_check<- subset(hdi_check, hdi_check$location !="Hong Kong")
summary(hdi_check)
unique(covid_data$location)
unique(hdi_check$location)
#write.csv(x=hdi_check, file="Covid_Cleansed_HDI_Check.csv")
#write.csv(x=hdi_check_no_missing, file="hdi_check_no_missing.csv")
unique(hdi_check$gdp_per_capita)
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
unique(hdi_cleansed$location)
cols = c(1:3, 25)
hdi_cleansed = hdi_cleansed[-cols]
hdi_cleansed$date =
cor(hdi_cleansed)
ggplot(hdi_cleansed,aes(date,new_cases)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
geom_line() +
scale_y_continuous(trans = "log2")
hdi_cleansed %>% group_by(location) %>% mutate(Growth = (new_cases - lag(new_cases))/lag(new_cases))
hdi_check %>% group_by(location) %>% mutate(Growth = (new_cases - lag(new_cases))/lag(new_cases))
hdi_check$growth_factor = hdi_check %>% group_by(location) %>% mutate(Growth = (new_cases - lag(new_cases))/lag(new_cases))
View(hdi_check)
View(hdi_check)
View(hdi_check)
hdi_check$growth_factor
View(hdi_check)
library(readxl)
covid_data <- read_excel("covid-data.xlsx",
col_types = c("text", "text", "text",
"text", "numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "text", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
summary(covid_data)
#changing the date column class from "character" to "date" type
class(covid_data$date)
covid_data$date <- as.Date(covid_data$date)
class(covid_data$date)
# covid_data has 50,350 obs of 41 variables
# interpolation via spline method for the missing values in chosen columns
# library(zoo)
# covid_data$life_expectancy <-  na.spline(covid_data$life_expectancy)
# summary(covid_data$life_expectancy)
##### HDI ####
hdi_check <- filter(covid_data, covid_data$human_development_index >= 0.915)
unique(hdi_check$location)
hdi_check = mutate(hdi_check, percent_pop_infected = hdi_check$total_cases/hdi_check$population)
hdi_check$percent_pop_infected = hdi_check$percent_pop_infected * 100
hdi_check$percent_pop_infected = round(hdi_check$percent_pop_infected, 2)
# dropped columns with more than 50% missing data
hdi_check <-  hdi_check[,!sapply(hdi_check, function(x) mean(is.na(x)))>0.5]
summary(hdi_check)
which(is.na(hdi_check$gdp_per_capita)) ### this shows it is Lichenstein
hdi_check<- subset(hdi_check, hdi_check$location !="Liechtenstein")
hdi_check<- subset(hdi_check, hdi_check$location !="Hong Kong")
summary(hdi_check)
unique(covid_data$location)
unique(hdi_check$location)
#write.csv(x=hdi_check, file="Covid_Cleansed_HDI_Check.csv")
#write.csv(x=hdi_check_no_missing, file="hdi_check_no_missing.csv")
unique(hdi_check$gdp_per_capita)
hdi_cleansed <- hdi_check[complete.cases(hdi_check), ]
unique(hdi_cleansed$location)
cols = c(1:3, 25)
hdi_cleansed = hdi_cleansed[-cols]
hdi_cleansed$date =
hdi_check %>% group_by(location) %>% mutate(Growth = (new_cases - lag(new_cases))/lag(new_cases))
hdi_check %>% group_by(location) %>% mutate(Growth = (new_cases - lag(date))/lag(date))
hdi_check %>% group_by(location) %>% mutate(Growth = lag(new_cases))
View(hdi_check)
lag(hdi_check$new_cases, 7)
hdi_check %>% mutate(Growht_Factor = lag(hdi_check$new_cases, 7))
View(hdi_check)
hdi_check$growth_factor = lag(hdi_check$new_cases, 7)
View(hdi_check)
hdi_check$growth_factor = (lag(hdi_check$new_cases, 7) / lead(hdi_check$new_cases, 7)) * 100
View(hdi_check)
hdi_check$growth_factor = (lag(hdi_check$new_cases, 7) / lead(hdi_check$new_cases, 7)) * 1
View(hdi_check)
hdi_check$growth_factor = round(hdi_check$growth_factor, digits =  2)
View(hdi_check)
ggplot(hdi_check, aes(x=date, y = growth_factor, color = location)) +
geom_point()
ggplot(hdi_check, aes(x=date, y = growth_factor, color = location)) +
geom_line()
hypo_testing = read_csv("hdi_check_no_missing.csv")
hypo_testing = read_csv("hdi_check_no_missing_new.csv")
hypo_testing <- read_excel("hdi_check_no_missing_new.xlsx",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
View(hypo_testing)
install.packages("mulcompView")
install.packages("multcompView")
install.packages("multcompView")
library(multcompView)
library(multcompView)
install.packages("multcompView")
aov(new_cases ~ ., hypo_testing)
anova_one_way = aov(new_cases ~ ., hypo_testing)
summary(anova_one_way)
anova_one_way = aov(new_cases ~ ., hdi_check)
summary(anova_one_way)
anova_one_way = aov(new_cases ~ ., hdi_check_no_missing)
summary(anova_one_way)
anova_one_way = aov(new_cases ~ ., hdi_cleansed)
summary(anova_one_way)
TurkeyHSD(anova_one_way)
anova_one_way = aov(new_cases ~ ., hypo_testing)
summary(anova_one_way)
anova_one_way = aov(new_cases ~ ., hdi_check_no_missing)
summary(anova_one_way)
View(hdi_check_no_missing)
anova_one_way = aov(total_cases ~ location, hdi_check_no_missing)
summary(anova_one_way)
cor(hdi_cleansed)
cor(hdi_cleansed[2:37])
corPlot(hdi_cleansed[2:37])
install.packages("corrplot")
install.packages("corrplot")
library(corrplot)
corrplot(hdi_cleansed[2:37])
cor = corrplot(hdi_cleansed[2:37])
cor = cor(hdi_cleansed[2:37])
corPlot(cor, method = "circle")
corrplot(cor, method = "circle")
corrplot(cor, method = "color")
cor = cor(hypo_testing)
corrplot(cor, method = "color")
cor = cor(hypo_testing[2:15])
corrplot(cor, method = "color")
cor = cor(hdi_cleansed[2:37])
corrplot(cor, method = "color")
res1 <- cor.mtest(mtcars, conf.level = .95)
res1 <- cor.mtest(hdi_cleansed[2:37], conf.level = .95)
## specialized the insignificant value according to the significant level
corrplot(M, p.mat = res1$p, sig.level = .2)
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, sig.level = .2)
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, insig = "blank")
cor = cor(hypo_testing[2:15])
res1 <- cor.mtest(hdi_cleansed[2:37], conf.level = .95)
res1 <- cor.mtest(hypo_testing[2:15], conf.level = .95)
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, insig = "blank")
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, sig.level = .05)
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, sig.level = .1)
## specialized the insignificant value according to the significant level
corrplot(cor, p.mat = res1$p, sig.level = .01)
cor = cor(hypo_testing[2:15])
corrplot(cor, method = "color")
